{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d15d8294-3328-4e07-ad16-8a03e9bbfdb9",
   "metadata": {},
   "source": [
    "# Welcome to your first assignment!\n",
    "\n",
    "Instructions are below. Please give this a try, and look in the solutions folder if you get stuck (or feel free to ask me!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada885d9-4d42-4d9b-97f0-74fbbbfe93a9",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Just before we get to the assignment --</h2>\n",
    "            <span style=\"color:#f71;\">I thought I'd take a second to point you at this page of useful resources for the course. This includes links to all the slides.<br/>\n",
    "            <a href=\"https://edwarddonner.com/2024/11/13/llm-engineering-resources/\">https://edwarddonner.com/2024/11/13/llm-engineering-resources/</a><br/>\n",
    "            Please keep this bookmarked, and I'll continue to add more useful links there over time.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9fa1fc-eac5-4d1d-9be4-541b3f2b3458",
   "metadata": {},
   "source": [
    "# HOMEWORK EXERCISE ASSIGNMENT\n",
    "\n",
    "Upgrade the day 1 project to summarize a webpage to use an Open Source model running locally via Ollama rather than OpenAI\n",
    "\n",
    "You'll be able to use this technique for all subsequent projects if you'd prefer not to use paid APIs.\n",
    "\n",
    "**Benefits:**\n",
    "1. No API charges - open-source\n",
    "2. Data doesn't leave your box\n",
    "\n",
    "**Disadvantages:**\n",
    "1. Significantly less power than Frontier Model\n",
    "\n",
    "## Recap on installation of Ollama\n",
    "\n",
    "Simply visit [ollama.com](https://ollama.com) and install!\n",
    "\n",
    "Once complete, the ollama server should already be running locally.  \n",
    "If you visit:  \n",
    "[http://localhost:11434/](http://localhost:11434/)\n",
    "\n",
    "You should see the message `Ollama is running`.  \n",
    "\n",
    "If not, bring up a new Terminal (Mac) or Powershell (Windows) and enter `ollama serve`  \n",
    "And in another Terminal (Mac) or Powershell (Windows), enter `ollama pull llama3.2`  \n",
    "Then try [http://localhost:11434/](http://localhost:11434/) again.\n",
    "\n",
    "If Ollama is slow on your machine, try using `llama3.2:1b` as an alternative. Run `ollama pull llama3.2:1b` from a Terminal or Powershell, and change the code below from `MODEL = \"llama3.2\"` to `MODEL = \"llama3.2:1b\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29ddd15d-a3c5-4f4e-a678-873f56162724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "\n",
    "OLLAMA_API = \"http://localhost:11434/api/chat\"\n",
    "HEADERS = {\"Content-Type\": \"application/json\"}\n",
    "MODEL = \"llama3.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dac0a679-599c-441f-9bf2-ddc73d35b940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a messages list using the same format that we used for OpenAI\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Describe some of the business applications of Generative AI\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7bb9c624-14f0-4945-a719-8ddb64f66f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {\n",
    "        \"model\": MODEL,\n",
    "        \"messages\": messages,\n",
    "        \"stream\": False\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479ff514-e8bd-4985-a572-2ea28bb4fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just make sure the model is loaded\n",
    "\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "42b9f644-522d-4e05-a691-56e7658c0ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries, including:\n",
      "\n",
      "1. **Content Generation**: AI can generate high-quality content such as articles, social media posts, product descriptions, and more. This can help reduce content creation costs and increase efficiency.\n",
      "2. **Customer Service Chatbots**: Generative AI-powered chatbots can provide 24/7 customer support, answering common questions and resolving issues in a personalized manner.\n",
      "3. **Product Design and Development**: AI can generate 3D models, prototypes, and product designs, reducing the need for manual drafting and improving product development speed.\n",
      "4. **Marketing and Advertising**: Generative AI can create personalized advertisements, social media posts, and email campaigns, increasing engagement and conversion rates.\n",
      "5. **Data Analysis and Visualization**: AI can analyze large datasets and generate insights, visualizations, and predictions, helping businesses make data-driven decisions.\n",
      "6. **Automated Content Moderation**: Generative AI-powered systems can detect and remove inappropriate content from social media platforms, ensuring a safer online environment.\n",
      "7. **Language Translation**: AI-powered language translation tools can help businesses communicate with international customers, increasing global reach and revenue.\n",
      "8. **Financial Modeling and Forecasting**: Generative AI can analyze financial data, generate forecasts, and predict market trends, helping businesses make informed investment decisions.\n",
      "9. **Product Recommendation Systems**: AI-powered recommendation engines can suggest products to customers based on their preferences, increasing sales and customer satisfaction.\n",
      "10. **Digital Asset Management**: Generative AI can automate the management of digital assets, such as images, videos, and audio files, reducing storage costs and improving content organization.\n",
      "\n",
      "Some specific business applications of Generative AI include:\n",
      "\n",
      "* **Automated product description generation**: AI can generate high-quality product descriptions based on product features, specifications, and customer reviews.\n",
      "* **Personalized email marketing**: Generative AI can analyze customer data and generate personalized email campaigns that increase engagement and conversion rates.\n",
      "* **Custom content creation for social media**: AI can create engaging social media content, such as posts, stories, and reels, increasing brand visibility and reach.\n",
      "* **Automated chatbot conversations**: Generative AI-powered chatbots can engage in natural-sounding conversations with customers, improving customer support and satisfaction.\n",
      "* **Predictive maintenance and quality control**: AI can analyze sensor data from manufacturing processes and predict equipment failures, reducing downtime and improving product quality.\n",
      "\n",
      "Overall, Generative AI has the potential to revolutionize various business applications, increasing efficiency, productivity, and revenue while improving customer experiences.\n"
     ]
    }
   ],
   "source": [
    "# If this doesn't work for any reason, try the 2 versions in the following cells\n",
    "# And double check the instructions in the 'Recap on installation of Ollama' at the top of this lab\n",
    "# And if none of that works - contact me!\n",
    "\n",
    "response = requests.post(OLLAMA_API, json=payload, headers=HEADERS)\n",
    "print(response.json()['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a021f13-d6a1-4b96-8e18-4eae49d876fe",
   "metadata": {},
   "source": [
    "# Introducing the ollama package\n",
    "\n",
    "And now we'll do the same thing, but using the elegant ollama python package instead of a direct HTTP call.\n",
    "\n",
    "Under the hood, it's making the same call as above to the ollama server running at localhost:11434"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20218472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ollama\n",
      "  Downloading ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in /home/me/myenv/lib/python3.12/site-packages (from ollama) (0.27.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.9.0 in /home/me/myenv/lib/python3.12/site-packages (from ollama) (2.9.2)\n",
      "Requirement already satisfied: anyio in /home/me/myenv/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (4.6.2.post1)\n",
      "Requirement already satisfied: certifi in /home/me/myenv/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /home/me/myenv/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (1.0.6)\n",
      "Requirement already satisfied: idna in /home/me/myenv/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /home/me/myenv/lib/python3.12/site-packages (from httpx<0.29,>=0.27->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /home/me/myenv/lib/python3.12/site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /home/me/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /home/me/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/me/myenv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.9.0->ollama) (4.12.2)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.4.7\n"
     ]
    }
   ],
   "source": [
    "!pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7745b9c4-57dc-4867-9180-61fa5db55eb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generative AI has numerous business applications across various industries. Here are some examples:\n",
      "\n",
      "1. **Content Generation**: Generative AI can be used to create high-quality, engaging content such as blog posts, social media posts, product descriptions, and more. This can help businesses save time and resources while maintaining consistency in their content.\n",
      "2. **Image and Video Creation**: Generative AI can generate images and videos that are indistinguishable from those created by humans. This can be used for marketing materials, product visuals, and more.\n",
      "3. **Product Design**: Generative AI can assist designers in creating new product concepts, reducing the need for manual design and iteration.\n",
      "4. **Chatbots and Virtual Assistants**: Generative AI can power chatbots and virtual assistants, enabling businesses to provide personalized customer experiences and automate routine tasks.\n",
      "5. **Predictive Maintenance**: Generative AI can analyze sensor data from industrial equipment and predict when maintenance is needed, reducing downtime and increasing productivity.\n",
      "6. **Personalized Marketing**: Generative AI can help create personalized marketing campaigns by analyzing customer data and behavior, and suggesting targeted messaging and offers.\n",
      "7. **Recommendation Systems**: Generative AI can improve recommendation systems by generating personalized product suggestions based on user behavior and preferences.\n",
      "8. **Autonomous Writing Tools**: Generative AI-powered writing tools can assist writers with research, organization, and even content generation, freeing up time for more complex tasks.\n",
      "9. **Creative Collaboration**: Generative AI can facilitate creative collaboration between humans and machines, enabling the co-creation of new ideas and products.\n",
      "10. **Data Analysis and Insights**: Generative AI can help analyze large datasets and generate insights that inform business decisions, such as market trends and customer behavior.\n",
      "\n",
      "Industries where Generative AI has the most potential for disruption include:\n",
      "\n",
      "1. **Marketing and Advertising**\n",
      "2. **Content Creation and Publishing**\n",
      "3. **Product Design and Development**\n",
      "4. **Customer Service and Support**\n",
      "5. **Finance and Banking**\n",
      "6. **Healthcare and Medical Research**\n",
      "7. **Education and Training**\n",
      "\n",
      "These are just a few examples of the many business applications of Generative AI. As the technology continues to evolve, we can expect to see even more innovative uses across various industries.\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(model=MODEL, messages=messages)\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4704e10-f5fb-4c15-a935-f046c06fb13d",
   "metadata": {},
   "source": [
    "## Alternative approach - using OpenAI python library to connect to Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23057e00-b6fc-4678-93a9-6b31cb704bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's actually an alternative approach that some people might prefer\n",
    "# You can use the OpenAI client python library to call Ollama:\n",
    "\n",
    "from openai import OpenAI\n",
    "ollama_via_openai = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=MODEL,\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7d1de3-e2ac-46ff-a302-3b4ba38c4c90",
   "metadata": {},
   "source": [
    "## Also trying the amazing reasoning model DeepSeek\n",
    "\n",
    "Here we use the version of DeepSeek-reasoner that's been distilled to 1.5B.  \n",
    "This is actually a 1.5B variant of Qwen that has been fine-tuned using synethic data generated by Deepseek R1.\n",
    "\n",
    "Other sizes of DeepSeek are [here](https://ollama.com/library/deepseek-r1) all the way up to the full 671B parameter version, which would use up 404GB of your drive and is far too large for most!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9eb44e-fe5b-47aa-b719-0bb63669ab3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ollama pull deepseek-r1:1.5b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3d554b-e00d-4c08-9300-45e073950a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This may take a few minutes to run! You should then see a fascinating \"thinking\" trace inside <think> tags, followed by some decent definitions\n",
    "\n",
    "response = ollama_via_openai.chat.completions.create(\n",
    "    model=\"deepseek-r1:1.5b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Please give definitions of some core concepts behind LLMs: a neural network, attention and the transformer\"}]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1622d9bb-5c68-4d4e-9ca4-b492c751f898",
   "metadata": {},
   "source": [
    "# NOW the exercise for you\n",
    "\n",
    "Take the code from day1 and incorporate it here, to build a website summarizer that uses Llama 3.2 running locally instead of OpenAI; use either of the above approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de38216-6d1c-48c4-877b-86d403f4e0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
