{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## What is Ollama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MS9vPBDDkd6"
      },
      "source": [
        "## Running Ollama on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This file is based on:\n",
        "https://github.com/ed-donner/llm_engineering/blob/main/README.md"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Download and Install Ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZcqFHYODOBO"
      },
      "outputs": [],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3-RFec0EMwI"
      },
      "source": [
        "## When this completes..\n",
        "\n",
        "The cell above should now say: `Install complete. Run \"ollama\" from the command line.`\n",
        "\n",
        "Now click in the cell below and press Shift+Enter.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_j3vwuDHDwxI"
      },
      "outputs": [],
      "source": [
        "# Start Ollama server\n",
        "\n",
        "import subprocess\n",
        "\n",
        "# Start the command in a background process\n",
        "process = subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "# The kernel can continue execution while the process runs in the background\n",
        "print(\"The 'ollama serve' process is running in the background.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jx6JAHmKEkOs"
      },
      "source": [
        "# Great!\n",
        "\n",
        "It should now say above: `The 'ollama serve' process is running in the background`.\n",
        "\n",
        "Now press Shift+Enter in each of the cells below in turn to try out Ollama."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3VSOQYiGzco"
      },
      "outputs": [],
      "source": [
        "# Download the model that we want to use - this might take a couple of mins\n",
        "# The exclamation mark at the start of the line indicates that this is a shell command, not python\n",
        "\n",
        "!ollama pull llama3.2:1b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gr4iQ6alDqdf"
      },
      "outputs": [],
      "source": [
        "# install the Ollama python API package\n",
        "\n",
        "!pip install ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZ7EoToiDqaq"
      },
      "outputs": [],
      "source": [
        "# import the package\n",
        "\n",
        "import ollama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZA2T87uWCMKl"
      },
      "outputs": [],
      "source": [
        "# Your first message to your very own LLM running \"locally\" (well, on your cloud box)\n",
        "\n",
        "message = \"Hi there! This is my first message to an LLM!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uIRqzV2jDLLJ"
      },
      "outputs": [],
      "source": [
        "# Put this message into the format expected by Ollama\n",
        "\n",
        "messages = [{\"role\": \"user\", \"content\": message}]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qehl86LOAuzQ"
      },
      "outputs": [],
      "source": [
        "# Let's do this!!\n",
        "\n",
        "response = ollama.chat(model=\"llama3.2:1b\", messages=messages)\n",
        "print(response['message']['content'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9GZvqvzFTmU"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
